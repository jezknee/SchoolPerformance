---
title: "R Notebook"
output: html_notebook
---



```{r}
education_data <- read.csv("C:\\Users\\jezkn\\Local\\Data Science Projects\\School Data\\2023-2024\\Data\\output.csv")
head(education_data)
```
```{r}
colnames(education_data)
education_data2 <- subset(education_data, select = -c(RECTYPE,URN, NFTYPE, RELDENOM, ADMPOL_PT, EGENDER, PGPUP, P8PUP, LEA,ESTAB,SCHNAME,PCODE,PCON_CODE,PCON_NAME,FEEDER,oa21cd,ladcd,LSOA_code,ATT8SCR))
id_cols <- c("MSOA_code")
ed <- education_data2[!is.na(education_data$MSOA_code),]
all_na_cols <- names(ed)[colSums(is.na(ed)) > 0]

na_counts <- colSums(is.na(ed))
na_counts[na_counts > 0]

ed_nulls <- ed[, c(id_cols, setdiff(names(ed), id_cols))]

head(ed_nulls)

numeric_cols <- sapply(ed_nulls, is.numeric)

column_averages <- aggregate(
  ed_nulls[, numeric_cols], 
  by = list(MSOA_code = ed_nulls$MSOA_code), 
  FUN = mean,
  na.rm = TRUE
)

head(column_averages)

ed_test <- education_data
my_dataframe_merged <- merge(ed_test, column_averages, 
                              by = "MSOA_code", suffixes = c("", "_avg"), all.x = TRUE)

# Replace NAs only where both original and average exist
for(col in names(ed_test)[numeric_cols]) {
  avg_col <- paste0(col, "_avg")
  if(avg_col %in% names(my_dataframe_merged)) {
    na_indices <- is.na(my_dataframe_merged[[col]])
    my_dataframe_merged[[col]][na_indices] <- my_dataframe_merged[[avg_col]][na_indices]
  }
}

# Remove the _avg columns and keep original structure
ed_test <- my_dataframe_merged[, names(ed_test)]

head(ed_test)

```

```{r}
df <- subset(ed_test, select = -c(RECTYPE,LEA,ESTAB,SCHNAME,PCODE,PCON_CODE,PCON_NAME,FEEDER,oa21cd,LSOA_code,MSOA_code,ladcd))
head(df,50)
```
```{r}
library(tidyverse)

df <- df %>%
  mutate(dummy=1) %>%
  pivot_wider(names_from=NFTYPE, values_from=dummy, values_fill=0, names_prefix = "SCHOOL_TYPE_") %>%
  mutate(dummy=1) %>%
  pivot_wider(names_from=ADMPOL_PT, values_from=dummy, values_fill=0, names_prefix = "ADMISSIONS_POLICY_") %>%
  mutate(dummy=1) %>%
  pivot_wider(names_from=EGENDER, values_from=dummy, values_fill=0, names_prefix = "SCHOOL_GENDER_") %>%
  mutate(dummy=1) %>%
  pivot_wider(names_from=RELDENOM, values_from=dummy, values_fill=0, names_prefix = "SCHOOL_RELIGION_")

head(df)
```
```{r}
df_check <- subset(df, select = -c(URN, PGPUP,P8PUP))
df_check <- df_check %>%
  mutate(ATT8SCR = as.numeric(ATT8SCR))
head(df_check)

df_check.cor <- data.frame(cor(df_check, use = "pairwise.complete.obs"))
df_check.cor
```
```{r}

df_check.cor <- as.matrix(df_check.cor)

library(reshape2)

# Convert correlation matrix to long format
df_long <- melt(df_check.cor)

# The result will have columns: Var1, Var2, value
# You can rename them if you want:
colnames(df_long) <- c("Variable1", "Variable2", "Correlation")

head(df_long)


write.csv(df_long, "C:\\Users\\jezkn\\Local\\Data Science Projects\\School Data\\2023-2024\\Data\\correlation_matrix2.csv", row.names = TRUE)
#library(corrplot)
#corrplot(df_check.cor)
```
```{r}
df2 <- df[, !grepl("ADMISSIONS_POLICY", colnames(df))]
df2 <- df2[, !grepl("SCHOOL_TYPE", colnames(df2))]
df2 <- df2[, !grepl("SCHOOL_GENDER", colnames(df2))]
#df2 <- df2[, !grepl("IMD_Children", colnames(df2))]
#df2 <- df2[, !grepl("IMD_Education", colnames(df2))]

df2 <- subset(df2, select = -c(IMD_Children,IMD_Education,PGPUP,P8PUP))

df2$Performance <- cut(as.numeric(df2$ATT8SCR), breaks=c(0,10,20,30,40,50,60,70,200), labels=c("0-10","10-20","20-30","30-40","40-50","50-60","60-70","70+"))
df2 <- subset(df2, select = -c(ATT8SCR))

head(df2)
```
```{r}
#
```

```{r}
library(caret)

#df2 <- subset(df2, select = -c(URN))
nzv <- nearZeroVar(df2, saveMetrics = TRUE)
df2_clean <- df2[, !nzv$nzv]
ncol(df2_clean)
```
```{r}
head(df2_clean)
#cor_matrix <- cor(df2_clean[sapply(df2_clean, is.numeric)], use = "complete.obs")

# Find and remove highly correlated variables (>0.9 correlation)
#high_cor <- findCorrelation(cor_matrix, cutoff = 0.9)
#df2_clean <- df2_clean[, -high_cor]
```

```{r}
library(nnet)
library(randomForest)
set.seed(42)

#use 70% of dataset as training set and 30% as test set
sample <- sample(c(TRUE, FALSE), nrow(df2), replace=TRUE, prob=c(0.7,0.3))
train  <- df2_clean[sample, ]
test   <- df2_clean[!sample, ]

rf_model <- randomForest(Performance ~ ., data = train, importance = TRUE)
summary(rf_model)

#glm.fits <- multinom(
#  Performance ~ .,
#  data = train
#)
#summary(glm.fits)

```
```{r}

```

